# OpenShift Virtualization Performance Suite on Azure

This repository contains an automated benchmark harness for evaluating
**OpenShift Virtualization on Azure Red Hat OpenShift (ARO)**.  
It compares Pods vs. KubeVirt VMs on **D96s v5/v6 worker nodes** with
**ODF (Ceph) storage**, and produces both raw results and seller-friendly
summaries (CSV, Markdown, PDF, charts).

This code was generated by GPT5. I make no claims to quality or authorship.

---

## Cluster Prerequisites

- ARO or OpenShift 4.x cluster with:
  - **Worker nodes** in the target family (`D96s v5` and/or `D96s v6`).
  - ODF (OpenShift Data Foundation) deployed with Ceph RBD + CephFS storageclasses.
- Access to the cluster API from where you run the tests (`oc login` must work).
- Sufficient quota in Azure for the large D96s SKUs.
- Node labels applied (examples):

  ```bash
  oc label node -l "node.kubernetes.io/instance-type=Standard_D96s_v5" sku.family=dsv5-large --overwrite
  oc label node -l "node.kubernetes.io/instance-type=Standard_D96s_v6" sku.family=dsv6-large --overwrite
  ```

Alternatively, you can install a fresh ARO cluster and follow the instructions for Preparing a Fresh Cluster(#Preparing-a-Fresh-Cluster) below.

---

## Running the Tests

You can run the suite three ways:

### 1. Locally (from your laptop/home Linux machine)

Prerequisites:

* `oc` CLI installed and logged into the cluster.
* `podman` (preferred) or `docker`.

Run with the provided Makefile:

```bash
# OOTB profile on D96s v5
make PROFILE=ootb FAMILY=v5 run

# STRICT profile on D96s v6
make strict
make PROFILE=strict FAMILY=v6 run
```

Results will appear in `results/`. To build seller artifacts:

```bash
make seller-pack
```

#### One-liner (direct container run)

If you want to bypass the Makefile and just run the container:

```bash
podman run --rm \
  -v $(pwd)/suites:/suites \
  -v $(pwd)/results:/results \
  -v $KUBECONFIG:/root/.kube/config:ro \
  quay.io/redhat-performance/benchmark-runner:latest \
  --config /suites/aro-ootb-d96s-v5.yaml
```

(Substitute `docker run` if you use Docker.)

---

### 2. Via GitHub Actions (manual trigger)

* Push this repo to a GitHub project with Actions enabled.
* Go to **Actions → manual-perf → Run workflow**.
* Choose inputs:

  * `profile`: `ootb` or `strict`
  * `family`: `v5` or `v6`
* The workflow will run tests against your cluster (requires `OC_API` and `OC_TOKEN` secrets).
* Artifacts (`results/**`, `seller-pack/**`) will be downloadable from the workflow run.

---

### 3. From a Bastion Host Inside the Cluster

If you prefer to run from a bastion VM that has cluster access:

```bash
# SSH to bastion
ssh user@bastion

# Ensure oc + podman/docker installed
oc whoami

# Clone repo
git clone <this-repo>
cd perf-suite

# Trigger
make PROFILE=ootb FAMILY=v5 run
```

Results will be stored locally on the bastion in `results/`.

---

## Outputs

* `results/` — raw JSON/metrics from benchmark-runner.
* `seller-pack/` — seller-friendly outputs:

  * `summary.csv`, `summary.md`, `summary.pdf`
  * simple bar charts per workload

---

## Preparing a Fresh Cluster

If you provisioned a brand-new ARO/OpenShift cluster, you can take it from
“fresh install” to “ready for perf tests” automatically with:

```bash
make prep
````

This does the following:

* Upgrades the cluster to a target OCP version (configurable via `$TARGET_OCP_VERSION`).
* Ensures a minimum worker pool size of the desired VM SKU (defaults to 6 × D96s v5).
* Installs and configures ODF (Ceph RBD + CephFS).
* Installs and configures OpenShift Virtualization (CNV).
* Ensures wrapper StorageClasses (`odf-rbd`, `odf-cephfs`) exist.

The script will wait for operators and clusters to become ready.
It may take ~20–30 minutes depending on scaling and operator installs.

After `make prep` completes, run the tests as usual:

```bash
make PROFILE=ootb FAMILY=v5 run
```

Or for strict profile on D96s v6:

```bash
make strict
make PROFILE=strict FAMILY=v6 run
```

---

## Notes

* Tests target **96 vCPU workers** only.
* Profiles:

  * **ootb**: default tuning.
  * **strict**: PAO/kubelet config for CPU pinning, hugepages, NUMA alignment.
* ODF throughput expectations differ between SATA-backed (`v5`) and NVMe-enabled (`v6`) families.
* For sizing ODF disk pools, see `sizing/odf_sizer.py`.


